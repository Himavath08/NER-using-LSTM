{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPixkK55f8hHvAnjxe0Gt9B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ulWwpLb8U7by"},"outputs":[],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from torch.nn.utils.rnn import pad_sequence\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",""]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"],"metadata":{"id":"dDpK9rUYU-J_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\").ffill()\n","words = list(data[\"Word\"].unique())\n","tags = list(data[\"Tag\"].unique())\n","\n","if \"ENDPAD\" not in words:\n","    words.append(\"ENDPAD\")\n","\n","word2idx = {w: i + 1 for i, w in enumerate(words)}\n","tag2idx = {t: i for i, t in enumerate(tags)}\n","idx2tag = {i: t for t, i in tag2idx.items()}"],"metadata":{"id":"aOku5iL0VLa4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.head(50)"],"metadata":{"id":"wIqIfM1UVdpy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Unique words in corpus:\", data['Word'].nunique())\n","print(\"Unique tags in corpus:\", data['Tag'].nunique())"],"metadata":{"id":"ZansQ5d0Vm7w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Unique tags are:\", tags)"],"metadata":{"id":"5g-0KyPXVqQJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SentenceGetter:\n","    def __init__(self, data):\n","        self.grouped = data.groupby(\"Sentence #\", group_keys=False).apply(\n","            lambda s: [(w, t) for w, t in zip(s[\"Word\"], s[\"Tag\"])]\n","        )\n","        self.sentences = list(self.grouped)\n","\n","getter = SentenceGetter(data)\n","sentences = getter.sentences"],"metadata":{"id":"rE1mNPGWVvj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences[35]"],"metadata":{"id":"mct4tDNBVwoA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = [[word2idx[w] for w, t in s] for s in sentences]\n","y = [[tag2idx[t] for w, t in s] for s in sentences]\n",""],"metadata":{"id":"Cx-XV_ktVzYx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["word2idx"],"metadata":{"id":"K8AgKKu0V2vV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.hist([len(s) for s in sentences], bins=50)\n","plt.show()"],"metadata":{"id":"_6vSs2IrV8B3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_len = 50\n","X_pad = pad_sequence([torch.tensor(seq) for seq in X], batch_first=True, padding_value=word2idx[\"ENDPAD\"])\n","y_pad = pad_sequence([torch.tensor(seq) for seq in y], batch_first=True, padding_value=tag2idx[\"O\"])\n","X_pad = X_pad[:, :max_len]\n","y_pad = y_pad[:, :max_len]"],"metadata":{"id":"i0JqelwDWAFh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_pad[0]"],"metadata":{"id":"XftQMMe1WDNU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pad[0]"],"metadata":{"id":"totjgaUnWEAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X_pad, y_pad, test_size=0.2, random_state=1)"],"metadata":{"id":"ts7yhFkMWGyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NERDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            \"input_ids\": self.X[idx],\n","            \"labels\": self.y[idx]\n","        }\n","\n","train_loader = DataLoader(NERDataset(X_train, y_train), batch_size=32, shuffle=True)\n","test_loader = DataLoader(NERDataset(X_test, y_test), batch_size=32)\n"],"metadata":{"id":"Rdd4vhrDWI8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BiLSTMTagger(nn.Module):\n","  def __init__(self, vocab_size, tagset_size, embedding_dim = 50, hidden_dim = 100):\n","    super(BiLSTMTagger, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    self.dropout = nn.Dropout(0,1)\n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n","    self.fc = nn.Linear(hidden_dim * 2, tagset_size)\n","\n","  def forward(self, x):\n","    x = self.embedding(x)\n","    x = self.dropout(x)\n","    x, _ = self.lstm(x)\n","    return self.fc(x)"],"metadata":{"id":"ZN2uNZiHWLFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = BiLSTMTagger(len(word2idx)+1, len(tag2idx)).to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"],"metadata":{"id":"e7th8sNaWNjB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=3):\n","    train_losses, val_losses = [], []\n","    for epoch in range(epochs):\n","      model.train()\n","      total_loss = 0\n","      for batch in train_loader:\n","        input_ids = batch[\"input_ids\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","        optimizer.zero_grad()\n","        outputs = model(input_ids)\n","        loss = loss_fn(outputs.view(-1, len(tag2idx)), labels.view(-1))\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","      train_losses.append(total_loss)\n","\n","      model.eval()\n","      val_loss = 0\n","      with torch.no_grad():\n","        for batch in test_loader:\n","          input_ids = batch[\"input_ids\"].to(device)\n","          labels = batch['labels'].to(device)\n","          outputs = model(input_ids)\n","          loss = loss_fn(outputs.view(-1, len(tag2idx)), labels.view(-1))\n","          val_loss += loss.item()\n","      val_losses.append(val_loss)\n","      print(f\"Epoch {epoch+1}: Train Loss = {total_loss:.4f}, Val Loss = {val_loss:.4f}\")\n","\n","    return train_losses, val_losses"],"metadata":{"id":"OsDh9tTiWSFx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model(model, test_loader, X_test, y_test):\n","    model.eval()\n","    true_tags, pred_tags = [], []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            input_ids = batch[\"input_ids\"].to(device)\n","            labels = batch[\"labels\"].to(device)\n","            outputs = model(input_ids)\n","            preds = torch.argmax(outputs, dim=-1)\n","            for i in range(len(labels)):\n","                for j in range(len(labels[i])):\n","                    if labels[i][j] != tag2idx[\"O\"]:\n","                        true_tags.append(idx2tag[labels[i][j].item()])\n","                        pred_tags.append(idx2tag[preds[i][j].item()])\n","\n","train_losses, val_losses = train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=3)\n","evaluate_model(model, test_loader, X_test, y_test)"],"metadata":{"id":"fibR17X-WfXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run training and evaluation\n","train_losses, val_losses = train_model(model, train_loader, test_loader, loss_fn, optimizer, epochs=3)\n","evaluate_model(model, test_loader, X_test, y_test)"],"metadata":{"id":"FJZa4Ad5WixG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Name: Himavath M')\n","print('Register Number: 212223240053')\n","history_df = pd.DataFrame({\"loss\": train_losses, \"val_loss\": val_losses})\n","history_df.plot(title=\"Loss Over Epochs\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"10u6784jWk7Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["i = 125\n","model.eval()\n","sample = X_test[i].unsqueeze(0).to(device)\n","output = model(sample)\n","preds = torch.argmax(output, dim=-1).squeeze().cpu().numpy()\n","true = y_test[i].numpy()\n","\n","print('Name: Himavath M')\n","print('Register Number: 212223240053')\n","print(\"{:<15} {:<10} {}\\n{}\".format(\"Word\", \"True\", \"Pred\", \"-\" * 40))\n","for w_id, true_tag, pred_tag in zip(X_test[i], y_test[i], preds):\n","    if w_id.item() != word2idx[\"ENDPAD\"]:\n","        word = words[w_id.item() - 1]\n","        true_label = tags[true_tag.item()]\n","        pred_label = tags[pred_tag]\n","        print(f\"{word:<15} {true_label:<10} {pred_label}\")"],"metadata":{"id":"qg0yhXkbWu6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AJEEofJnW1R3"},"execution_count":null,"outputs":[]}]}